---
layout: post
title: Why AI Isn't Alive (Yet)
date: 2024-10-1
categories: Reflections
---
# Implications of internal and external sources of reward
## Bridging Human and AI Learning through Reinforcement

Reinforcement learning generalizes any machine learning model that is trained with an objective function, which includes virtually all recent and past applications. RL specializes in handling a  reward signal that changes as an agent interacts with an environment but this can be trivialized to a constant signal and applied to any prediction problem where the loss is a fixed function of the model's output and the ground truth. 

Viewing all machine learning as RL allows us to draw a parallel with theories of reinforcement learning in the human brain. Reinforcement learning stems from Skinner's theory of operant conditioning and more generally, the branch of cognitive scientists called behavioralists. Behavioralists suggested that virtually any behavior can be learned by providing positive and negative "reinforcements" thereby rewarding behavior that is similar to the desired outcome and discouraging dissimilar behavior. This theory helps explain a wide variety of human and animal behavior and also finds itself rooted in distributed brain systems dedicated to this type of learning--namely, the dopaminergic reward system. This reward system in the brain is responsible for our strong urge to seek out things that bring us both long and short-term pleasure. This relates to how patterns of addiction arise from drug use and how we develop preferences in art and music. 

The reward system in the human brain draws mathematical equivalence to RL algorithms. Neuroscientists identified changes in dopamine levels at the neuronal level that account for a prediction-error, which is the difference between the expected and received reward. This prediction-error that is measured in the human brain has been shown to function similarly to the prediction-error that is defined in classical RL techniques such as TD learning. 

Reinforcement learning also provides a theoretical framework for how we learn more abstractly through statistical associations. The finding that the brain minimizes a prediction-error as it learns is consistent with Friston's "free energy principle", which states that in order to optimally interact with its environment, the brain makes predictions using a learned prior akin to Bayesian inference models. Indeed, statistical learning has become a powerful lens through which to view the human acquisition of even more abstract forms of meaning like language and music. And similarly, defying expectations, large language models like GPT have shown that a statistical framework of predicting the next word in a string of text is enough to develop an emergent understanding of human language and even sentience and emotion...

The extent to which Chat GPT 